#include "kafka_client.h"

// é”™è¯¯ç å®šä¹‰
enum {
    KAFKA_OK = 0,
    KAFKA_ERROR = 1,
    KAFKA_ERROR_CREATE_CLIENT = 2,
    KAFKA_ERROR_CONFIG = 3,
    KAFKA_ERROR_CONNECT = 4,
    KAFKA_ERROR_TOPICS = 5,
    KAFKA_ERROR_SEND = 6,
    KAFKA_ERROR_SUBSCRIBE = 7,
    KAFKA_ERROR_CONSUME = 8,
};

// é”™è¯¯ä¿¡æ¯
static const char* error_messages[] = {
    "Success",
    "General error",
    "Failed to create client",
    "Configuration error",
    "Connection error",
    "Failed to get topics",
    "Failed to send message",
    "Failed to subscribe to topic",
    "Failed to consume message",
};

// Kafkaç”Ÿäº§è€…ä¸Šä¸‹æ–‡
typedef struct {
    rd_kafka_t* rk;
} KafkaProducer;

// Kafkaæ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
typedef struct {
    rd_kafka_t* rk;
    rd_kafka_topic_partition_list_t* topic_list;
} KafkaConsumer;

// Kafkaæ¶ˆæ¯ä¸Šä¸‹æ–‡
typedef struct {
    char* content;
    char* key;
    char* topic;
    int64_t offset;
    int32_t partition;
    int64_t timestamp;
} KafkaMessage;

// åˆ›å»ºKafkaç”Ÿäº§è€…
KafkaClientHandle create_kafka_producer(const char* bootstrap_servers) {
    rd_kafka_t* rk;
    rd_kafka_conf_t* conf;
    char errstr[512];
    
    printf("ğŸ”§ C: create_kafka_producer called with bootstrap_servers: %s\n", bootstrap_servers);
    
    // åˆ›å»ºé…ç½®
    conf = rd_kafka_conf_new();
    if (!conf) {
        printf("âŒ C: Failed to create Kafka configuration\n");
        return NULL;
    }
    
    // è®¾ç½®bootstrap servers
    if (rd_kafka_conf_set(conf, "bootstrap.servers", bootstrap_servers, errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
        printf("âŒ C: Failed to set bootstrap.servers: %s\n", errstr);
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // è®¾ç½®å®¢æˆ·ç«¯ID
    if (rd_kafka_conf_set(conf, "client.id", "flutter-kafka-producer", errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
        printf("âŒ C: Failed to set client.id: %s\n", errstr);
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // åˆ›å»ºç”Ÿäº§è€…å®ä¾‹
    rk = rd_kafka_new(RD_KAFKA_PRODUCER, conf, errstr, sizeof(errstr));
    if (!rk) {
        printf("âŒ C: Failed to create Kafka producer: %s\n", errstr);
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // åˆ†é…ç”Ÿäº§è€…ä¸Šä¸‹æ–‡
    KafkaProducer* producer = malloc(sizeof(KafkaProducer));
    if (!producer) {
        printf("âŒ C: Failed to allocate memory for producer\n");
        rd_kafka_destroy(rk);
        return NULL;
    }
    
    producer->rk = rk;
    printf("âœ… C: Successfully created Kafka producer\n");
    return producer;
}

// åˆ›å»ºKafkaæ¶ˆè´¹è€…
KafkaClientHandle create_kafka_consumer(const char* bootstrap_servers, const char* group_id) {
    // é»˜è®¤ä½¿ç”¨earlieståç§»é‡é‡ç½®ç­–ç•¥
    return create_kafka_consumer_with_config(bootstrap_servers, group_id, "earliest");
}

// åˆ›å»ºå¸¦æ¶ˆè´¹ä½ç½®é…ç½®çš„Kafkaæ¶ˆè´¹è€…
KafkaClientHandle create_kafka_consumer_with_config(const char* bootstrap_servers, const char* group_id, const char* auto_offset_reset) {
    rd_kafka_t* rk;
    rd_kafka_conf_t* conf;
    char errstr[512];
    
    // åˆ›å»ºé…ç½®
    conf = rd_kafka_conf_new();
    if (!conf) {
        return NULL;
    }
    
    // è®¾ç½®bootstrap servers
    if (rd_kafka_conf_set(conf, "bootstrap.servers", bootstrap_servers, errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // è®¾ç½®æ¶ˆè´¹è€…ç»„ID
    if (rd_kafka_conf_set(conf, "group.id", group_id, errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // è®¾ç½®å®¢æˆ·ç«¯ID
    if (rd_kafka_conf_set(conf, "client.id", "flutter-kafka-consumer", errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // è®¾ç½®è‡ªåŠ¨åç§»é‡ç½®ç­–ç•¥
    if (rd_kafka_conf_set(conf, "auto.offset.reset", auto_offset_reset, errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // è®¾ç½®å¯ç”¨è‡ªåŠ¨æäº¤
    if (rd_kafka_conf_set(conf, "enable.auto.commit", "true", errstr, sizeof(errstr)) != RD_KAFKA_CONF_OK) {
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // åˆ›å»ºæ¶ˆè´¹è€…å®ä¾‹
    rk = rd_kafka_new(RD_KAFKA_CONSUMER, conf, errstr, sizeof(errstr));
    if (!rk) {
        rd_kafka_conf_destroy(conf);
        return NULL;
    }
    
    // åˆ†é…æ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
    KafkaConsumer* consumer = malloc(sizeof(KafkaConsumer));
    if (!consumer) {
        rd_kafka_destroy(rk);
        return NULL;
    }
    
    consumer->rk = rk;
    consumer->topic_list = NULL;
    return consumer;
}

// å…³é—­Kafkaå®¢æˆ·ç«¯
void close_kafka_client(KafkaClientHandle client) {
    if (!client) {
        return;
    }
    
    // å…ˆå°è¯•ä½œä¸ºç”Ÿäº§è€…å¤„ç†
    KafkaProducer* producer = (KafkaProducer*)client;
    rd_kafka_t* rk = producer->rk;
    
    if (rd_kafka_type(rk) == RD_KAFKA_PRODUCER) {
        // é”€æ¯ç”Ÿäº§è€…
        rd_kafka_flush(producer->rk, 5000);
        rd_kafka_destroy(producer->rk);
        free(producer);
    } else {
        // ä½œä¸ºæ¶ˆè´¹è€…å¤„ç†
        KafkaConsumer* consumer = (KafkaConsumer*)client;
        // å–æ¶ˆè®¢é˜…
        if (consumer->topic_list) {
            rd_kafka_topic_partition_list_destroy(consumer->topic_list);
        }
        // å…³é—­æ¶ˆè´¹è€…
        rd_kafka_consumer_close(consumer->rk);
        rd_kafka_destroy(consumer->rk);
        free(consumer);
    }
}

// è·å–ä¸»é¢˜åˆ—è¡¨
char** get_kafka_topics(KafkaClientHandle client, int32_t* topic_count) {
    if (!client || !topic_count) {
        printf("âŒ C: get_kafka_topics - Invalid parameters: client=%p, topic_count=%p\n", client, topic_count);
        return NULL;
    }
    
    printf("ğŸ”§ C: get_kafka_topics - Client handle received: %p\n", client);
    rd_kafka_t* rk = ((KafkaProducer*)client)->rk;
    printf("ğŸ”§ C: get_kafka_topics - Kafka client pointer: %p\n", rk);
    const struct rd_kafka_metadata* metadata;
    
    // å‘brokerè¯·æ±‚å…ƒæ•°æ®
    printf("ğŸ”§ C: get_kafka_topics - Calling rd_kafka_metadata...\n");
    rd_kafka_resp_err_t err = rd_kafka_metadata(
        rk,                 // å®¢æˆ·ç«¯
        1,                  // åŒ…æ‹¬ä¸»é¢˜å…ƒæ•°æ®
        NULL,               // ç‰¹å®šä¸»é¢˜ï¼ˆNULLè¡¨ç¤ºæ‰€æœ‰ä¸»é¢˜ï¼‰
        &metadata,          // è¾“å‡ºå…ƒæ•°æ®
        5000);              // è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    
    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
        printf("âŒ C: get_kafka_topics - Failed to get metadata: %s\n", rd_kafka_err2str(err));
        return NULL;
    }
    
    printf("âœ… C: get_kafka_topics - Successfully got metadata\n");
    printf("ğŸ”§ C: get_kafka_topics - Broker count: %d\n", metadata->broker_cnt);
    printf("ğŸ”§ C: get_kafka_topics - Topic count: %d\n", metadata->topic_cnt);
    
    // åˆ†é…ä¸»é¢˜åç§°æ•°ç»„
    char** topic_names = malloc(metadata->topic_cnt * sizeof(char*));
    if (!topic_names) {
        printf("âŒ C: get_kafka_topics - Failed to allocate memory for topic names\n");
        rd_kafka_metadata_destroy(metadata);
        return NULL;
    }
    
    // å¤åˆ¶ä¸»é¢˜åç§°ï¼Œè¿‡æ»¤å†…éƒ¨ä¸»é¢˜
    int32_t actual_topic_count = 0;
    for (int i = 0; i < metadata->topic_cnt; i++) {
        const struct rd_kafka_metadata_topic* topic = &metadata->topics[i];
        printf("ğŸ” C: get_kafka_topics - Topic %d: %s\n", i, topic->topic);
        
        // è¿‡æ»¤å†…éƒ¨ä¸»é¢˜ï¼ˆä»¥__å¼€å¤´ï¼‰
        if (strncmp(topic->topic, "__", 2) == 0) {
            printf("â­ï¸  C: get_kafka_topics - Skipping internal topic: %s\n", topic->topic);
            continue;
        }
        
        topic_names[actual_topic_count] = strdup(topic->topic);
        if (!topic_names[actual_topic_count]) {
            // æ¸…ç†å·²åˆ†é…çš„å†…å­˜
            for (int j = 0; j < actual_topic_count; j++) {
                if (topic_names[j]) {
                    free(topic_names[j]);
                }
            }
            free(topic_names);
            rd_kafka_metadata_destroy(metadata);
            printf("âŒ C: get_kafka_topics - Failed to duplicate topic name\n");
            return NULL;
        }
        actual_topic_count++;
    }
    
    printf("ğŸ”§ C: get_kafka_topics - Actual topic count (excluding internal): %d\n", actual_topic_count);
    
    // å¦‚æœæœ‰è·³è¿‡çš„å†…éƒ¨ä¸»é¢˜ï¼Œé‡æ–°åˆ†é…å†…å­˜
    if (actual_topic_count < metadata->topic_cnt && actual_topic_count > 0) {
        char** filtered_topic_names = realloc(topic_names, actual_topic_count * sizeof(char*));
        if (!filtered_topic_names) {
            // å¦‚æœreallocå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸæ•°ç»„
            printf("âš ï¸  C: get_kafka_topics - Failed to realloc topic names, using original array\n");
        } else {
            topic_names = filtered_topic_names;
        }
    } else if (actual_topic_count == 0) {
        free(topic_names);
        topic_names = NULL;
    }
    
    *topic_count = actual_topic_count;
    printf("âœ… C: get_kafka_topics - Returning %d topics\n", actual_topic_count);
    
    rd_kafka_metadata_destroy(metadata);
    return topic_names;
}

// é‡Šæ”¾ä¸»é¢˜åˆ—è¡¨
void free_kafka_topics(char** topics, int32_t topic_count) {
    if (!topics || topic_count <= 0) {
        return;
    }
    
    for (int i = 0; i < topic_count; i++) {
        free(topics[i]);
    }
    free(topics);
}

// å‘é€æ¶ˆæ¯
KafkaErrorCode send_kafka_message(KafkaClientHandle producer, const char* topic, const char* message) {
    if (!producer || !topic || !message) {
        return KAFKA_ERROR;
    }
    
    KafkaProducer* p = (KafkaProducer*)producer;
    rd_kafka_t* rk = p->rk;
    
    // åˆ›å»ºä¸»é¢˜
    rd_kafka_topic_t* rkt = rd_kafka_topic_new(rk, topic, NULL);
    if (!rkt) {
        return KAFKA_ERROR_SEND;
    }
    
    // å‘é€æ¶ˆæ¯
    rd_kafka_resp_err_t err = rd_kafka_produce(
        rkt,                                   // ä¸»é¢˜
        RD_KAFKA_PARTITION_UA,                 // è‡ªåŠ¨åˆ†åŒº
        RD_KAFKA_MSG_F_COPY,                   // å¤åˆ¶æ¶ˆæ¯å†…å®¹
        (void*)message,                        // æ¶ˆæ¯å†…å®¹
        strlen(message),                       // æ¶ˆæ¯é•¿åº¦
        NULL,                                  // é”®
        0,                                     // é”®é•¿åº¦
        NULL);                                 // ç§æœ‰æ•°æ®
    
    // é”€æ¯ä¸»é¢˜
    rd_kafka_topic_destroy(rkt);
    
    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
        return KAFKA_ERROR_SEND;
    }
    
    // åˆ·æ–°ç”Ÿäº§è€…ä»¥ç¡®ä¿æ¶ˆæ¯å‘é€
    rd_kafka_flush(rk, 5000);
    return KAFKA_OK;
}

// è®¢é˜…ä¸»é¢˜
KafkaErrorCode subscribe_kafka_topic(KafkaClientHandle consumer, const char* topic) {
    if (!consumer || !topic) {
        return KAFKA_ERROR;
    }
    
    KafkaConsumer* c = (KafkaConsumer*)consumer;
    rd_kafka_t* rk = c->rk;
    
    // åˆ›å»ºæˆ–æ›´æ–°ä¸»é¢˜åˆ—è¡¨
    if (c->topic_list) {
        rd_kafka_topic_partition_list_destroy(c->topic_list);
    }
    
    c->topic_list = rd_kafka_topic_partition_list_new(1);
    if (!c->topic_list) {
        return KAFKA_ERROR_SUBSCRIBE;
    }
    
    // æ·»åŠ ä¸»é¢˜åˆ°åˆ—è¡¨
    rd_kafka_topic_partition_list_add(c->topic_list, topic, RD_KAFKA_PARTITION_UA);
    
    // è®¢é˜…ä¸»é¢˜
    rd_kafka_resp_err_t err = rd_kafka_subscribe(rk, c->topic_list);
    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
        return KAFKA_ERROR_SUBSCRIBE;
    }
    
    return KAFKA_OK;
}

// æ¶ˆè´¹æ¶ˆæ¯
KafkaMessageHandle consume_kafka_message(KafkaClientHandle consumer, int32_t timeout_ms) {
    if (!consumer) {
        return NULL;
    }
    
    KafkaConsumer* c = (KafkaConsumer*)consumer;
    rd_kafka_t* rk = c->rk;
    
    // æ¶ˆè´¹æ¶ˆæ¯
    rd_kafka_message_t* rkmessage = rd_kafka_consumer_poll(rk, timeout_ms);
    if (!rkmessage) {
        return NULL;  // è¶…æ—¶
    }
    
    // æ£€æŸ¥é”™è¯¯
    if (rkmessage->err) {
        rd_kafka_message_destroy(rkmessage);
        return NULL;
    }
    
    // åˆ›å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡
    KafkaMessage* message = malloc(sizeof(KafkaMessage));
    if (!message) {
        rd_kafka_message_destroy(rkmessage);
        return NULL;
    }
    
    // å¤åˆ¶æ¶ˆæ¯å†…å®¹
    if (rkmessage->payload && rkmessage->len > 0) {
        message->content = malloc(rkmessage->len + 1);
        if (!message->content) {
            free(message);
            rd_kafka_message_destroy(rkmessage);
            return NULL;
        }
        memcpy(message->content, rkmessage->payload, rkmessage->len);
        message->content[rkmessage->len] = '\0';
    } else {
        message->content = strdup("");
    }
    
    // å¤åˆ¶æ¶ˆæ¯key
    if (rkmessage->key && rkmessage->key_len > 0) {
        message->key = malloc(rkmessage->key_len + 1);
        if (!message->key) {
            free(message->content);
            free(message);
            rd_kafka_message_destroy(rkmessage);
            return NULL;
        }
        memcpy(message->key, rkmessage->key, rkmessage->key_len);
        message->key[rkmessage->key_len] = '\0';
    } else {
        message->key = strdup("");
    }
    
    // å¤åˆ¶ä¸»é¢˜åç§°
    if (rkmessage->rkt) {
        message->topic = strdup(rd_kafka_topic_name(rkmessage->rkt));
    } else {
        message->topic = strdup("");
    }
    
    message->offset = rkmessage->offset;
    message->partition = rkmessage->partition;
    
    // è·å–æ¶ˆæ¯æ—¶é—´æˆ³
    rd_kafka_timestamp_type_t ts_type;
    message->timestamp = rd_kafka_message_timestamp(rkmessage, &ts_type);
    
    rd_kafka_message_destroy(rkmessage);
    return message;
}

// è·å–æ¶ˆæ¯å†…å®¹
const char* get_kafka_message_content(KafkaMessageHandle message) {
    if (!message) {
        return NULL;
    }
    
    KafkaMessage* msg = (KafkaMessage*)message;
    return msg->content;
}

// è·å–æ¶ˆæ¯ä¸»é¢˜
const char* get_kafka_message_topic(KafkaMessageHandle message) {
    if (!message) {
        return NULL;
    }
    
    KafkaMessage* msg = (KafkaMessage*)message;
    return msg->topic;
}

// è·å–æ¶ˆæ¯åç§»é‡
int64_t get_kafka_message_offset(KafkaMessageHandle message) {
    if (!message) {
        return -1;
    }
    
    KafkaMessage* msg = (KafkaMessage*)message;
    return msg->offset;
}

// è·å–æ¶ˆæ¯åˆ†åŒº
int32_t get_kafka_message_partition(KafkaMessageHandle message) {
    if (!message) {
        return -1;
    }
    
    KafkaMessage* msg = (KafkaMessage*)message;
    return msg->partition;
}

// è·å–æ¶ˆæ¯key
const char* get_kafka_message_key(KafkaMessageHandle message) {
    if (!message) {
        return NULL;
    }
    
    KafkaMessage* msg = (KafkaMessage*)message;
    return msg->key;
}

// è·å–æ¶ˆæ¯æ—¶é—´æˆ³
int64_t get_kafka_message_timestamp(KafkaMessageHandle message) {
    if (!message) {
        return -1;
    }
    
    KafkaMessage* msg = (KafkaMessage*)message;
    return msg->timestamp;
}

// é‡ç½®æ¶ˆè´¹è€…åç§»é‡åˆ°ç‰¹å®šæ—¶é—´æˆ³
KafkaErrorCode seek_to_timestamp(KafkaClientHandle consumer, const char* topic, int64_t timestamp_ms) {
    if (!consumer || !topic) {
        return KAFKA_ERROR;
    }
    
    KafkaConsumer* c = (KafkaConsumer*)consumer;
    rd_kafka_t* rk = c->rk;
    rd_kafka_topic_partition_list_t* partitions;
    int i;
    
    // è·å–ä¸»é¢˜çš„æ‰€æœ‰åˆ†åŒº
    partitions = rd_kafka_topic_partition_list_new(0);
    if (!partitions) {
        return KAFKA_ERROR;
    }
    
    // è·å–åˆ†åŒºåˆ—è¡¨
    const struct rd_kafka_metadata* metadata;
    rd_kafka_resp_err_t err = rd_kafka_metadata(rk, 1, rd_kafka_topic_new(rk, topic, NULL), &metadata, 5000);
    rd_kafka_topic_destroy(rd_kafka_topic_new(rk, topic, NULL));
    
    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
        rd_kafka_topic_partition_list_destroy(partitions);
        return KAFKA_ERROR;
    }
    
    // éå†æ‰€æœ‰åˆ†åŒº
    for (i = 0; i < metadata->topic_cnt; i++) {
        const struct rd_kafka_metadata_topic* meta_topic = &metadata->topics[i];
        if (strcmp(meta_topic->topic, topic) == 0) {
            // ä¸ºæ¯ä¸ªåˆ†åŒºè®¾ç½®è¦æŸ¥æ‰¾çš„æ—¶é—´æˆ³
            for (int j = 0; j < meta_topic->partition_cnt; j++) {
                const struct rd_kafka_metadata_partition* meta_partition = &meta_topic->partitions[j];
                rd_kafka_topic_partition_t* rktpar = rd_kafka_topic_partition_list_add(partitions, topic, meta_partition->id);
                rktpar->offset = timestamp_ms;
            }
            break;
        }
    }
    
    rd_kafka_metadata_destroy(metadata);
    
    if (partitions->cnt == 0) {
        rd_kafka_topic_partition_list_destroy(partitions);
        return KAFKA_ERROR;
    }
    
    // ä½¿ç”¨æ—¶é—´æˆ³æŸ¥æ‰¾åç§»é‡
    err = rd_kafka_offsets_for_times(rk, partitions, 5000);
    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
        rd_kafka_topic_partition_list_destroy(partitions);
        return KAFKA_ERROR;
    }
    
    // ä¸ºæ¯ä¸ªåˆ†åŒºè®¾ç½®åç§»é‡
    for (i = 0; i < partitions->cnt; i++) {
        rd_kafka_topic_partition_t* rktpar = &partitions->elems[i];
        if (rktpar->err != RD_KAFKA_RESP_ERR_NO_ERROR) {
            continue;
        }
        
        // ä½¿ç”¨seekè®¾ç½®åç§»é‡
        rd_kafka_topic_t* rkt = rd_kafka_topic_new(rk, rktpar->topic, NULL);
        if (!rkt) {
            rd_kafka_topic_partition_list_destroy(partitions);
            return KAFKA_ERROR;
        }
        
        err = rd_kafka_seek(rkt, rktpar->partition, rktpar->offset, 5000);
        rd_kafka_topic_destroy(rkt);
        
        if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
            rd_kafka_topic_partition_list_destroy(partitions);
            return KAFKA_ERROR;
        }
    }
    
    rd_kafka_topic_partition_list_destroy(partitions);
    return KAFKA_OK;
}

// é‡Šæ”¾æ¶ˆæ¯
void free_kafka_message(KafkaMessageHandle message) {
    if (!message) {
        return;
    }
    
    KafkaMessage* msg = (KafkaMessage*)message;
    if (msg->content) {
        free(msg->content);
    }
    if (msg->key) {
        free(msg->key);
    }
    if (msg->topic) {
        free(msg->topic);
    }
    free(msg);
}

// è·å–é”™è¯¯ä¿¡æ¯
const char* get_kafka_error_msg(KafkaErrorCode error_code) {
    if (error_code < 0 || error_code >= sizeof(error_messages) / sizeof(error_messages[0])) {
        return "Unknown error";
    }
    
    return error_messages[error_code];
}

// è·å–ä¸»é¢˜çš„åŸºæœ¬ä¿¡æ¯
KafkaErrorCode get_kafka_topic_info(
    KafkaClientHandle client,
    const char* topic_name,
    int32_t* partition_count,
    int32_t* replication_factor) {
    if (!client || !topic_name || !partition_count || !replication_factor) {
        printf("âŒ C: get_kafka_topic_info - Invalid parameters\n");
        return KAFKA_ERROR;
    }

    printf("ğŸ”§ C: get_kafka_topic_info called for topic: %s\n", topic_name);
    rd_kafka_t* rk = ((KafkaProducer*)client)->rk;
    const struct rd_kafka_metadata* metadata;

    // å‘brokerè¯·æ±‚å…ƒæ•°æ®
    rd_kafka_resp_err_t err = rd_kafka_metadata(
        rk,                 // å®¢æˆ·ç«¯
        1,                  // åŒ…æ‹¬ä¸»é¢˜å…ƒæ•°æ®
        NULL,               // ç‰¹å®šä¸»é¢˜ï¼ˆNULLè¡¨ç¤ºæ‰€æœ‰ä¸»é¢˜ï¼‰
        &metadata,          // è¾“å‡ºå…ƒæ•°æ®
        5000);              // è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
        printf("âŒ C: get_kafka_topic_info - Failed to get metadata: %s\n", rd_kafka_err2str(err));
        return KAFKA_ERROR;
    }

    printf("âœ… C: get_kafka_topic_info - Successfully got metadata with %d topics\n", metadata->topic_cnt);

    // æŸ¥æ‰¾æŒ‡å®šä¸»é¢˜
    for (int i = 0; i < metadata->topic_cnt; i++) {
        const struct rd_kafka_metadata_topic* topic = &metadata->topics[i];
        printf("ğŸ” C: Checking topic: %s (partitions: %d)\n", topic->topic, topic->partition_cnt);
        if (strcmp(topic->topic, topic_name) == 0) {
            // è®¾ç½®åˆ†åŒºæ•°é‡
            *partition_count = topic->partition_cnt;
            
            // è®¡ç®—å¹³å‡å‰¯æœ¬å› å­ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            int32_t total_replicas = 0;
            for (int j = 0; j < topic->partition_cnt; j++) {
                const struct rd_kafka_metadata_partition* partition = &topic->partitions[j];
                total_replicas += partition->replica_cnt;
            }
            *replication_factor = (total_replicas > 0 && topic->partition_cnt > 0) ? 
                                total_replicas / topic->partition_cnt : 0;
            
            printf("âœ… C: get_kafka_topic_info - Found topic %s with %d partitions and replication factor %d\n", 
                topic_name, *partition_count, *replication_factor);
            
            rd_kafka_metadata_destroy(metadata);
            return KAFKA_OK;
        }
    }

    printf("âŒ C: get_kafka_topic_info - Topic %s not found\n", topic_name);
    rd_kafka_metadata_destroy(metadata);
    return KAFKA_ERROR_TOPICS;  // ä¸»é¢˜ä¸å­˜åœ¨
}

// è·å–ä¸»é¢˜åˆ†åŒºè¯¦æƒ…
KafkaPartitionInfo* get_kafka_topic_partitions(
    KafkaClientHandle client,
    const char* topic_name,
    int32_t* partition_count) {
    if (!client || !topic_name || !partition_count) {
        printf("âŒ C: get_kafka_topic_partitions - Invalid parameters\n");
        return NULL;
    }

    printf("ğŸ”§ C: get_kafka_topic_partitions called for topic: %s\n", topic_name);
    rd_kafka_t* rk = ((KafkaProducer*)client)->rk;
    const struct rd_kafka_metadata* metadata;

    // å‘brokerè¯·æ±‚å…ƒæ•°æ®
    rd_kafka_resp_err_t err = rd_kafka_metadata(
        rk,                 // å®¢æˆ·ç«¯
        1,                  // åŒ…æ‹¬ä¸»é¢˜å…ƒæ•°æ®
        NULL,               // ç‰¹å®šä¸»é¢˜ï¼ˆNULLè¡¨ç¤ºæ‰€æœ‰ä¸»é¢˜ï¼‰
        &metadata,          // è¾“å‡ºå…ƒæ•°æ®
        5000);              // è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

    if (err != RD_KAFKA_RESP_ERR_NO_ERROR) {
        printf("âŒ C: get_kafka_topic_partitions - Failed to get metadata: %s\n", rd_kafka_err2str(err));
        return NULL;
    }

    printf("âœ… C: get_kafka_topic_partitions - Successfully got metadata with %d topics\n", metadata->topic_cnt);

    // æŸ¥æ‰¾æŒ‡å®šä¸»é¢˜
    const struct rd_kafka_metadata_topic* target_topic = NULL;
    for (int i = 0; i < metadata->topic_cnt; i++) {
        if (strcmp(metadata->topics[i].topic, topic_name) == 0) {
            target_topic = &metadata->topics[i];
            break;
        }
    }

    if (!target_topic) {
        printf("âŒ C: get_kafka_topic_partitions - Topic %s not found\n", topic_name);
        rd_kafka_metadata_destroy(metadata);
        return NULL;
    }

    printf("âœ… C: get_kafka_topic_partitions - Found topic %s with %d partitions\n", 
        topic_name, target_topic->partition_cnt);

    // åˆ†é…åˆ†åŒºä¿¡æ¯æ•°ç»„
    KafkaPartitionInfo* partitions = malloc(target_topic->partition_cnt * sizeof(KafkaPartitionInfo));
    if (!partitions) {
        rd_kafka_metadata_destroy(metadata);
        return NULL;
    }

    // å¡«å……åˆ†åŒºä¿¡æ¯
    for (int i = 0; i < target_topic->partition_cnt; i++) {
        const struct rd_kafka_metadata_partition* partition = &target_topic->partitions[i];
        partitions[i].id = partition->id;
        partitions[i].leader = partition->leader;

        // æ„å»ºå‰¯æœ¬åˆ—è¡¨å­—ç¬¦ä¸²
        char replicas_str[512] = "";
        for (int j = 0; j < partition->replica_cnt; j++) {
            if (j > 0) {
                strcat(replicas_str, ",");
            }
            char broker_id[16];
            sprintf(broker_id, "%d", partition->replicas[j]);
            strcat(replicas_str, broker_id);
        }
        partitions[i].replicas = strdup(replicas_str);

        // æ„å»ºISRåˆ—è¡¨å­—ç¬¦ä¸²
        char isr_str[512] = "";
        for (int j = 0; j < partition->isr_cnt; j++) {
            if (j > 0) {
                strcat(isr_str, ",");
            }
            char broker_id[16];
            sprintf(broker_id, "%d", partition->isrs[j]);
            strcat(isr_str, broker_id);
        }
        partitions[i].isr = strdup(isr_str);

        // è·å–çœŸå®çš„åç§»é‡
        int64_t low, high;
        rd_kafka_resp_err_t err = rd_kafka_query_watermark_offsets(
            rk, topic_name, partition->id, &low, &high, 5000);
        if (err == RD_KAFKA_RESP_ERR_NO_ERROR) {
            partitions[i].earliest_offset = low;
            partitions[i].latest_offset = high;
            printf("ğŸ” C: Partition %d - earliest_offset: %lld, latest_offset: %lld\n", 
                partition->id, low, high);
        } else {
            printf("âŒ C: Failed to get offsets for partition %d: %s\n", 
                partition->id, rd_kafka_err2str(err));
            partitions[i].earliest_offset = -1;  // è¡¨ç¤ºé”™è¯¯çŠ¶æ€
            partitions[i].latest_offset = -1;    // è¡¨ç¤ºé”™è¯¯çŠ¶æ€
        }
    }

    *partition_count = target_topic->partition_cnt;
    rd_kafka_metadata_destroy(metadata);
    return partitions;
}

// é‡Šæ”¾ä¸»é¢˜åˆ†åŒºè¯¦æƒ…
void free_kafka_topic_partitions(KafkaPartitionInfo* partitions, int32_t partition_count) {
    if (!partitions || partition_count <= 0) {
        return;
    }

    for (int i = 0; i < partition_count; i++) {
        if (partitions[i].replicas) {
            free(partitions[i].replicas);
        }
        if (partitions[i].isr) {
            free(partitions[i].isr);
        }
    }
    free(partitions);
}

// è·å–ä¸»é¢˜é…ç½®å‚æ•°
KafkaConfigParam* get_kafka_topic_config(
    KafkaClientHandle client,
    const char* topic_name,
    int32_t* param_count) {
    if (!client || !topic_name || !param_count) {
        printf("âŒ C: get_kafka_topic_config - Invalid parameters\n");
        return NULL;
    }

    printf("ğŸ”§ C: get_kafka_topic_config called for topic: %s\n", topic_name);
    
    // ç”±äºAPIå…¼å®¹æ€§é—®é¢˜ï¼Œè¿”å›ä¸€äº›åŸºæœ¬é…ç½®ä½œä¸ºåå¤‡
    *param_count = 4;
    KafkaConfigParam* params = malloc(4 * sizeof(KafkaConfigParam));
    if (!params) {
        return NULL;
    }
    
    params[0].key = strdup("retention.ms");
    params[0].value = strdup("604800000");  // 7å¤©
    
    params[1].key = strdup("cleanup.policy");
    params[1].value = strdup("delete");
    
    params[2].key = strdup("segment.bytes");
    params[2].value = strdup("1073741824");  // 1GB
    
    params[3].key = strdup("min.insync.replicas");
    params[3].value = strdup("1");
    
    printf("âœ… C: get_kafka_topic_config - Returned default config params\n");
    return params;
}

// é‡Šæ”¾ä¸»é¢˜é…ç½®å‚æ•°
void free_kafka_topic_config(KafkaConfigParam* params, int32_t param_count) {
    if (!params || param_count <= 0) {
        return;
    }

    for (int i = 0; i < param_count; i++) {
        if (params[i].key) {
            free(params[i].key);
        }
        if (params[i].value) {
            free(params[i].value);
        }
    }
    free(params);
}

// è·å–ä¸»é¢˜çš„æ¶ˆè´¹è€…ç»„
KafkaConsumerGroup* get_kafka_topic_consumer_groups(
    KafkaClientHandle client,
    const char* topic_name,
    int32_t* group_count) {
    if (!client || !topic_name || !group_count) {
        printf("âŒ C: get_kafka_topic_consumer_groups - Invalid parameters\n");
        return NULL;
    }

    printf("ğŸ”§ C: get_kafka_topic_consumer_groups called for topic: %s\n", topic_name);
    
    // ç”±äºAPIå…¼å®¹æ€§é—®é¢˜ï¼Œè¿”å›ç©ºç»“æœ
    *group_count = 0;
    printf("âœ… C: get_kafka_topic_consumer_groups - Returning 0 consumer groups\n");
    
    return NULL;  // è¿”å›NULLè¡¨ç¤ºæ²¡æœ‰æ‰¾åˆ°æ¶ˆè´¹è€…ç»„
}

// é‡Šæ”¾æ¶ˆè´¹è€…ç»„
void free_kafka_topic_consumer_groups(KafkaConsumerGroup* groups, int32_t group_count) {
    if (!groups || group_count <= 0) {
        return;
    }

    for (int i = 0; i < group_count; i++) {
        if (groups[i].name) {
            free(groups[i].name);
        }
        if (groups[i].status) {
            free(groups[i].status);
        }
    }
    free(groups);
}